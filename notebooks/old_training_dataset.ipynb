{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Prepare the setup",
   "id": "8b9c6268b8c4cee2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T07:21:18.223304Z",
     "start_time": "2025-05-28T07:21:18.217975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import packages\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T07:20:52.885748Z",
     "start_time": "2025-05-28T07:20:52.843821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"../data/old_training_dataset.csv\")"
   ],
   "id": "a2cf2b4dc31f15ba",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "First, we manually converted the dataset into a csv format because it is much easier to work with it.\n",
    "\n",
    "We are already familiar with data being in a tabular format, and since we encountered some issues with the original one, the arff, we found this solution as being quick and suitable.\n",
    "\n",
    "Initially we tried to make the conversion in code, but it did not work either."
   ],
   "id": "31bc6f312dc24291"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Initial exploration",
   "id": "f57f125e5ac4f702"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# See the first 5 rows\n",
    "df.head()"
   ],
   "id": "f49b658475e818aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "From the initial dataset, we decided to remove the first column that represented the index of each row, as it was unnecessary for the later implementation.",
   "id": "510f5cffc55fd086"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Print information about data\n",
    "df.info()"
   ],
   "id": "6d1c268c4ca3d289",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can see each column name with all the non-null values and their type. As we already noted in the dataset description, we expected everything to be integer.",
   "id": "b2fc1e8d2759a0f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.describe()",
   "id": "95291cc389432307",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can see basic statistical information such as count, mean, standard deviation, minimum value, the quartiles, and maximum value.",
   "id": "b584c9b5f71d2c08"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check for null values\n",
    "df.isna().sum()"
   ],
   "id": "b44de24784d16b8a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In this case, we don't have any missing values, an information we have already observed above.",
   "id": "794ece6435ffd929"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check for duplicates\n",
    "df.duplicated().sum()"
   ],
   "id": "676003b244758dc6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We expected to have duplicates because the dataset contains values like -1, 0 and 1. If we drop them, we lose the entire information that we need to work with.",
   "id": "f0e34a3a312a9ebf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# df.fillna(df.median(), inplace=True)  # or df.dropna() if very few rows",
   "id": "16608d95b6be95f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check target class\n",
    "df['Result'].value_counts()"
   ],
   "id": "b637a1b4ddffeccc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Convert types\n",
    "# df = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# Remove constant or duplicate columns\n",
    "# df = df.loc[:, df.nunique() > 1]"
   ],
   "id": "3355b32f3947bfc0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Check for class imbalance",
   "id": "ac394041fe5deb28"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Class distribution plot\n",
    "sns.countplot(x='Result', data=df)"
   ],
   "id": "5bda00e3edf43563",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We wanted to highlight and create a visualization for the information we just checked in the previous cell.\n",
    "\n",
    "As we can see, there is not a big difference between -1 and 1 in our target column, therefore we move on."
   ],
   "id": "f4b3bf2cf294c290"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# More visualizations",
   "id": "871814fa22b98d12"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Feature Correlation Heatmap",
   "id": "c7b0111641a79f54"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(df.corr(), cmap=\"coolwarm\", annot=False)\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.show()"
   ],
   "id": "64c2c9f5df1950d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This visualization shows us the relationship between all features including the target 'Result'.\n",
    "\n",
    "It is useful because it helps us detect multicollinearity. We learnt that too much correlation can affect some machine learning models, including, for example, linear ones. It could impact the future Logistic Regression model we want to implement, because it assumes feature independence.\n",
    "\n",
    "This is not the case. What we focused on were the bright pink or red points found outside the diagonal. They represent a strong correlation between variables."
   ],
   "id": "41957a8632277567"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Feature Correlation with 'Result'",
   "id": "29b2248c9f8eaa81"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "corr_with_target = df.corr()['Result'].drop('Result').sort_values()\n",
    "corr_with_target.plot(kind='barh', figsize=(8, 10), title=\"Feature Correlation with 'Result'\")\n",
    "plt.show()"
   ],
   "id": "e6b7ab9b8046df6e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We selected a horizontal bar because it is easier to read as we have quite a lot of features.\n",
    "\n",
    "What is important to mention:\n",
    "- Some positively correlate features are 'SSLfinal_State', 'URL_of_Anchor', and 'Prefix_Suffix'\n",
    "- Some negatively correlated features are 'Domain_registration_length' and 'Shortining_Service'\n",
    "\n",
    "These are candidates for stronger predictors\n",
    "\n",
    "What does not seem relevant at all are 'Favicon' and 'popUpWindnow'."
   ],
   "id": "be442509acb24c59"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Boxplot per class\n",
    "### 'SSLfinal_State' by 'Result'"
   ],
   "id": "51e0febf2c5abe42"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "feature = \"SSLfinal_State\"\n",
    "sns.boxplot(x='Result', y=feature, data=df)\n",
    "plt.title(f\"{feature} by Class\")\n",
    "plt.show()"
   ],
   "id": "21aef797e9bf4482",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sns.countplot(x='SSLfinal_State', data=df)",
   "id": "b11e91185f5eac55",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Pairplot with two highly relevant features vs 'Result'",
   "id": "76afd738720529c6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sns.pairplot(df[['SSLfinal_State','URL_of_Anchor','Result']], hue=\"Result\")",
   "id": "c4e334401f707656",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This visualization shows how 'SSLfinal_State' and 'URL_of_Anchor' vary between 'Result' values.\n",
    "\n",
    "- ... are grouped at -1\n",
    "- ... shift toward 1\n",
    "\n",
    "There is visible a strong separability."
   ],
   "id": "6a867071c2afa5f8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Split the data",
   "id": "69b965b7337d1303"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Separate the target first\n",
    "X = df.drop('Result', axis=1)\n",
    "y = df['Result']"
   ],
   "id": "3be7ac990ecbfeec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)"
   ],
   "id": "ccb9aa33aaa9ae45",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We applied an 80%-20% split using a random seed of 42. We included this seed as well, because we want to have consistent results. In this way, we make sure that we get the same split every time we run the code.",
   "id": "80906ce9f5eb2efe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot distributions\n",
    "df.hist(figsize=(12, 10))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "49c571575f89715e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We mainly included this plot because we wanted to check if scaling is required. As we can see, it is not required for most of the models because all the features are already in the same numeric range.\n",
    "\n",
    "However, we will scale the data because we also plan to use distance-based models."
   ],
   "id": "dae934d01bd68c6a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prepare a scaled version",
   "id": "de241c6b47cda1b8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit only on training data, transform both\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ],
   "id": "dcb1ee692036108d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training phase",
   "id": "665b03f4a3c43dea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Models to train\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1000),\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier()\n",
    "}\n",
    "\n",
    "# Scaled or not\n",
    "use_scaled = {\n",
    "    \"LogisticRegression\": True,\n",
    "    \"KNeighborsClassifier\": True,\n",
    "    \"DecisionTreeClassifier\": False,\n",
    "    \"RandomForestClassifier\": False\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "# Train and evaluate\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining: {name}\")\n",
    "\n",
    "    if use_scaled[name]:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        X_input = X_test_scaled\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        X_input = X_test\n",
    "\n",
    "    # Metrics\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred, zero_division=0),\n",
    "        \"Recall\": recall_score(y_test, y_pred, zero_division=0),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred, zero_division=0)\n",
    "    })\n",
    "\n",
    "    # Confusion Matrix\n",
    "    ConfusionMatrixDisplay.from_estimator(model, X_input, y_test)\n",
    "    plt.title(f\"{name} - Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "    # Feature Importance if available\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        importances = model.feature_importances_\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        feature_names = X.columns if not use_scaled[name] else X.columns  # same columns\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        sns.barplot(x=importances[indices], y=feature_names[indices])\n",
    "        plt.title(f\"{name} - Feature Importance\")\n",
    "        plt.show()\n",
    "\n",
    "# Show results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ],
   "id": "91bf9cb2c0a69c56",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
